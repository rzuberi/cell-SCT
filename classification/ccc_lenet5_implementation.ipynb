{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#source: https://blog.paperspace.com/writing-lenet5-from-scratch-in-python/\n",
    "#source: https://www.sciencedirect.com/science/article/pii/S0010482519303993?via%3Dihub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 3\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [15]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      3\u001B[0m df_821_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mrz200\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mDocuments\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mDevelopment\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mcell-SCT\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mclassification\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mimported_CSV\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdataframe_821\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      4\u001B[0m data_path \u001B[38;5;241m=\u001B[39m df_821_path\n\u001B[1;32m----> 5\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_821_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    580\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1255\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1253\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1255\u001B[0m     index, columns, col_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1257\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:225\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    224\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[1;32m--> 225\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    226\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m    227\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:805\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:883\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1026\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1072\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1147\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\core\\dtypes\\common.py:1474\u001B[0m, in \u001B[0;36mis_extension_array_dtype\u001B[1;34m(arr_or_dtype)\u001B[0m\n\u001B[0;32m   1429\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_extension_array_dtype\u001B[39m(arr_or_dtype) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m   1430\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1431\u001B[0m \u001B[38;5;124;03m    Check if an object is a pandas extension array type.\u001B[39;00m\n\u001B[0;32m   1432\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1472\u001B[0m \u001B[38;5;124;03m    False\u001B[39;00m\n\u001B[0;32m   1473\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1474\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m(arr_or_dtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, arr_or_dtype)\n\u001B[0;32m   1475\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, ExtensionDtype):\n\u001B[0;32m   1476\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_821_path = r'C:\\Users\\rz200\\Documents\\Development\\cell-SCT\\classification\\imported_CSV\\dataframe_821'\n",
    "data_path = df_821_path\n",
    "df = pd.read_csv(df_821_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 128   0   0]\n",
      "  [255 128   0   1]\n",
      "  [255 128   0   2]\n",
      "  ...\n",
      "  [  0   0 255 197]\n",
      "  [  0   0 255 198]\n",
      "  [  0   0 255 199]]\n",
      "\n",
      " [[255 128   0   0]\n",
      "  [255 128   0   1]\n",
      "  [255 128   0   2]\n",
      "  ...\n",
      "  [  0   0 255 197]\n",
      "  [  0   0 255 198]\n",
      "  [  0   0 255 199]]\n",
      "\n",
      " [[255 128   0   0]\n",
      "  [255 128   0   1]\n",
      "  [255 128   0   2]\n",
      "  ...\n",
      "  [  0   0 255 197]\n",
      "  [  0   0 255 198]\n",
      "  [  0   0 255 199]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 128   0   0]\n",
      "  [255 128   0   1]\n",
      "  [255 128   0   2]\n",
      "  ...\n",
      "  [  0   0 255 197]\n",
      "  [  0   0 255 198]\n",
      "  [  0   0 255 199]]\n",
      "\n",
      " [[255 128   0   0]\n",
      "  [255 128   0   1]\n",
      "  [255 128   0   2]\n",
      "  ...\n",
      "  [  0   0 255 197]\n",
      "  [  0   0 255 198]\n",
      "  [  0   0 255 199]]\n",
      "\n",
      " [[255 128   0   0]\n",
      "  [255 128   0   1]\n",
      "  [255 128   0   2]\n",
      "  ...\n",
      "  [  0   0 255 197]\n",
      "  [  0   0 255 198]\n",
      "  [  0   0 255 199]]]\n"
     ]
    }
   ],
   "source": [
    "array = np.zeros([100, 200, 4], dtype=np.uint8)\n",
    "array[:,:100] = [255, 128, 0, 255] #Orange left side\n",
    "array[:,100:] = [0, 0, 255, 255]   #Blue right side\n",
    "\n",
    "# Set transparency depending on x position\n",
    "for x in range(200):\n",
    "    for y in range(100):\n",
    "        array[y, x, 3] = x\n",
    "\n",
    "print(array)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 22)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x215595eda00>"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr_dapi = str2array(df['dapi_crops'][0])*255\n",
    "arr_cyclina2 = str2array(df['cyclina2_crops'][0])*255\n",
    "arr_edu = str2array(df['edu_crops'][0])*255\n",
    "arr_pcna = str2array(df['pcna_crops'][0])*255\n",
    "\n",
    "no_img = 4\n",
    "img = arr_dapi/no_img + arr_cyclina2/no_img + arr_edu/no_img + arr_pcna/no_img\n",
    "print(img.shape)\n",
    "plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20, 4)\n",
      "RGBA (20, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = 1000\n",
    "arr_dapi = str2array(df['dapi_crops'][img_id])*255\n",
    "arr_cyclina2 = str2array(df['cyclina2_crops'][img_id])*255\n",
    "arr_edu = str2array(df['edu_crops'][img_id])*255\n",
    "arr_pcna = str2array(df['pcna_crops'][img_id])*255\n",
    "\n",
    "arr = np.dstack((arr_dapi,arr_cyclina2,arr_edu,arr_pcna))\n",
    "arr = arr.astype(np.uint8)\n",
    "#arr = np.moveaxis(arr, -1, 0)\n",
    "#print(arr)\n",
    "print(arr.shape)\n",
    "\n",
    "#plt.imshow(arr.T)\n",
    "#im = Image.merge(\"RGB\",(arr_dapi,arr_cyclina2,arr_edu))\n",
    "im = Image.fromarray(arr)\n",
    "print(im.mode, im.size)\n",
    "#im = im.convert(\"L\")\n",
    "im.save('img_4_channels.png')\n",
    "for i in range(4):\n",
    "    plt.imshow(arr[...,i])\n",
    "    plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot understand given URI: array([[[ 1, 26,  1, 34],\n        [ 1, 26,  0, 33],\n     ....",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Input \u001B[1;32mIn [202]\u001B[0m, in \u001B[0;36m<cell line: 14>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     10\u001B[0m arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8)\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(arr))\n\u001B[1;32m---> 14\u001B[0m \u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\skimage\\io\\_io.py:53\u001B[0m, in \u001B[0;36mimread\u001B[1;34m(fname, as_gray, plugin, **plugin_args)\u001B[0m\n\u001B[0;32m     50\u001B[0m         plugin \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtifffile\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m file_or_url_context(fname) \u001B[38;5;28;01mas\u001B[39;00m fname:\n\u001B[1;32m---> 53\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43mcall_plugin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimread\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mplugin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplugin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mplugin_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(img, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\skimage\\io\\manage_plugins.py:207\u001B[0m, in \u001B[0;36mcall_plugin\u001B[1;34m(kind, *args, **kwargs)\u001B[0m\n\u001B[0;32m    203\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mIndexError\u001B[39;00m:\n\u001B[0;32m    204\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCould not find the plugin \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m    205\u001B[0m                            (plugin, kind))\n\u001B[1;32m--> 207\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:15\u001B[0m, in \u001B[0;36mimread\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(imageio_imread)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimread\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39masarray(\u001B[43mimageio_imread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\imageio\\v2.py:200\u001B[0m, in \u001B[0;36mimread\u001B[1;34m(uri, format, **kwargs)\u001B[0m\n\u001B[0;32m    197\u001B[0m imopen_args \u001B[38;5;241m=\u001B[39m decypher_format_arg(\u001B[38;5;28mformat\u001B[39m)\n\u001B[0;32m    198\u001B[0m imopen_args[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlegacy_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mimopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mri\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mimopen_args\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[0;32m    201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m file\u001B[38;5;241m.\u001B[39mread(index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\imageio\\core\\imopen.py:118\u001B[0m, in \u001B[0;36mimopen\u001B[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001B[0m\n\u001B[0;32m    116\u001B[0m     request\u001B[38;5;241m.\u001B[39mformat_hint \u001B[38;5;241m=\u001B[39m format_hint\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 118\u001B[0m     request \u001B[38;5;241m=\u001B[39m \u001B[43mRequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43muri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mio_mode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_hint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_hint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextension\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextension\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    120\u001B[0m source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<bytes>\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(uri, \u001B[38;5;28mbytes\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m uri\n\u001B[0;32m    122\u001B[0m \u001B[38;5;66;03m# fast-path based on plugin\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# (except in legacy mode)\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\imageio\\core\\request.py:248\u001B[0m, in \u001B[0;36mRequest.__init__\u001B[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001B[0m\n\u001B[0;32m    245\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid Request.Mode: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    247\u001B[0m \u001B[38;5;66;03m# Parse what was given\u001B[39;00m\n\u001B[1;32m--> 248\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43muri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# Set extension\u001B[39;00m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extension \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\imageio\\core\\request.py:369\u001B[0m, in \u001B[0;36mRequest._parse_uri\u001B[1;34m(self, uri)\u001B[0m\n\u001B[0;32m    367\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uri_r) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m60\u001B[39m:\n\u001B[0;32m    368\u001B[0m         uri_r \u001B[38;5;241m=\u001B[39m uri_r[:\u001B[38;5;241m57\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m...\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 369\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot understand given URI: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m uri_r)\n\u001B[0;32m    371\u001B[0m \u001B[38;5;66;03m# Check if this is supported\u001B[39;00m\n\u001B[0;32m    372\u001B[0m noWriting \u001B[38;5;241m=\u001B[39m [URI_HTTP, URI_FTP]\n",
      "\u001B[1;31mOSError\u001B[0m: Cannot understand given URI: array([[[ 1, 26,  1, 34],\n        [ 1, 26,  0, 33],\n     ...."
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "\n",
    "img_id = 1000\n",
    "arr_dapi = str2array(df['dapi_crops'][img_id])*255\n",
    "arr_cyclina2 = str2array(df['cyclina2_crops'][img_id])*255\n",
    "arr_edu = str2array(df['edu_crops'][img_id])*255\n",
    "arr_pcna = str2array(df['pcna_crops'][img_id])*255\n",
    "\n",
    "arr = np.dstack((arr_dapi,arr_cyclina2,arr_edu,arr_pcna))\n",
    "arr = arr.astype(np.uint8)\n",
    "\n",
    "print(type(arr))\n",
    "\n",
    "io.imread(arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [],
   "source": [
    "im=Image.open('img_4_channels.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Image' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [203]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(\u001B[43mim\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(im\u001B[38;5;241m.\u001B[39mmode, im\u001B[38;5;241m.\u001B[39msize)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'Image' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "plt.imshow(im[...,0])\n",
    "print(im.mode, im.size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/112027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rz200\\Documents\\development\\cell-SCT\\classification\\ccc_nn_functions.py:106: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(ast.literal_eval(s))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001/112027\n",
      "2001/112027\n",
      "3001/112027\n",
      "4001/112027\n",
      "5001/112027\n",
      "6001/112027\n",
      "7001/112027\n",
      "8001/112027\n",
      "9001/112027\n",
      "10001/112027\n",
      "11001/112027\n",
      "12001/112027\n",
      "13001/112027\n",
      "14001/112027\n",
      "15001/112027\n",
      "16001/112027\n",
      "17001/112027\n",
      "18001/112027\n",
      "19001/112027\n",
      "20001/112027\n",
      "21001/112027\n",
      "22001/112027\n",
      "23001/112027\n",
      "24001/112027\n",
      "25001/112027\n",
      "26001/112027\n",
      "27001/112027\n",
      "28001/112027\n",
      "29001/112027\n",
      "30001/112027\n",
      "31001/112027\n",
      "32001/112027\n",
      "33001/112027\n",
      "34001/112027\n",
      "35001/112027\n",
      "36001/112027\n",
      "37001/112027\n",
      "38001/112027\n",
      "39001/112027\n",
      "40001/112027\n",
      "41001/112027\n",
      "42001/112027\n",
      "43001/112027\n",
      "44001/112027\n",
      "45001/112027\n",
      "46001/112027\n",
      "47001/112027\n",
      "48001/112027\n",
      "49001/112027\n",
      "50001/112027\n",
      "51001/112027\n",
      "52001/112027\n",
      "53001/112027\n",
      "54001/112027\n",
      "55001/112027\n",
      "56001/112027\n",
      "57001/112027\n",
      "58001/112027\n",
      "59001/112027\n",
      "60001/112027\n",
      "61001/112027\n",
      "62001/112027\n",
      "63001/112027\n",
      "64001/112027\n",
      "65001/112027\n",
      "66001/112027\n",
      "67001/112027\n",
      "68001/112027\n",
      "69001/112027\n",
      "70001/112027\n",
      "71001/112027\n",
      "72001/112027\n",
      "73001/112027\n",
      "74001/112027\n",
      "75001/112027\n",
      "76001/112027\n",
      "77001/112027\n",
      "78001/112027\n",
      "79001/112027\n",
      "80001/112027\n",
      "81001/112027\n",
      "82001/112027\n",
      "83001/112027\n",
      "84001/112027\n",
      "85001/112027\n",
      "86001/112027\n",
      "87001/112027\n",
      "88001/112027\n",
      "89001/112027\n",
      "90001/112027\n",
      "91001/112027\n",
      "92001/112027\n",
      "93001/112027\n",
      "94001/112027\n",
      "95001/112027\n",
      "96001/112027\n",
      "97001/112027\n",
      "98001/112027\n",
      "99001/112027\n",
      "100001/112027\n",
      "101001/112027\n",
      "102001/112027\n",
      "103001/112027\n",
      "104001/112027\n",
      "105001/112027\n",
      "106001/112027\n",
      "107001/112027\n",
      "108001/112027\n",
      "109001/112027\n",
      "110001/112027\n",
      "111001/112027\n",
      "112001/112027\n",
      "225028/140034\n",
      "226028/140034\n",
      "227028/140034\n",
      "228028/140034\n",
      "229028/140034\n",
      "230028/140034\n",
      "231028/140034\n",
      "232028/140034\n",
      "233028/140034\n",
      "234028/140034\n",
      "235028/140034\n",
      "236028/140034\n",
      "237028/140034\n",
      "238028/140034\n",
      "239028/140034\n",
      "240028/140034\n",
      "241028/140034\n",
      "242028/140034\n",
      "243028/140034\n",
      "244028/140034\n",
      "245028/140034\n",
      "246028/140034\n",
      "247028/140034\n",
      "248028/140034\n",
      "249028/140034\n",
      "250028/140034\n",
      "251028/140034\n",
      "252028/140034\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from ccc_nn_functions import str2array\n",
    "\n",
    "def sort_training_and_testing_data(df,test_size=0.2):\n",
    "    shutil.rmtree('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\data')\n",
    "\n",
    "    #create a new dataframe where we shuffle the rows\n",
    "    df_shuffled = np.copy(df)\n",
    "    df_shuffled = df.sample(frac=1).reset_index(drop=True) #we could keep the index to keep for the cell names so its consistent with the first dataframe, would hepl later on\n",
    "    #df_shuffled = df[:10000]\n",
    "\n",
    "    total_images = len(df)\n",
    "    up_to = round((total_images-(total_images*test_size)))\n",
    "\n",
    "    #create a new column in that dataframe called 'ground_truth'\n",
    "    #for each row, if there is one True phase, that's the ground_truth\n",
    "    #if there are no True phase or more than two, the ground_truth is 'unclassified' for now\n",
    "    cycle_phase_encodings = []\n",
    "    for i in range(len(df_shuffled['S_Phase'])):\n",
    "        encoding_arr = []\n",
    "        if df_shuffled['G1_Phase'][i]: encoding_arr.append('g1_phase')\n",
    "        #else: encoding_arr.append(0)\n",
    "\n",
    "        if df_shuffled['S_Phase'][i]: encoding_arr.append('s_phase')\n",
    "        #else: encoding_arr.append(0)\n",
    "\n",
    "        if df_shuffled['G2_M_Phase'][i]: encoding_arr.append('g2_m_phase')\n",
    "        #else: encoding_arr.append(0)\n",
    "\n",
    "        if len(encoding_arr) != 1: encoding_arr = ['unclassified']\n",
    "\n",
    "        cycle_phase_encodings.append(encoding_arr)\n",
    "\n",
    "    df_shuffled['ground_truth'] = cycle_phase_encodings\n",
    "\n",
    "    #create a data directory\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data')\n",
    "\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\training_data')\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\training_data\\\\g1_phase')\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\training_data\\\\s_phase')\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\training_data\\\\g2_m_phase')\n",
    "\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\testing_data')\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\testing_data\\\\g1_phase')\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\testing_data\\\\s_phase')\n",
    "    os.mkdir('C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\testing_data\\\\g2_m_phase')\n",
    "\n",
    "    #take the first 1-test_size (0.8) and put them in the train folders\n",
    "    #create a training_data directory inside the data directory\n",
    "    #create an s_phase, g1_phase and g2_m_phase directories in there\n",
    "    #for each row in the first 0.8 of the dataframe, put the EdU numpy arrays in the corresponding folders\n",
    "    #last_train_row = round(0,up_to)\n",
    "    for i in range(0,up_to):\n",
    "        if i % 1000 == 0: print(str(i+1) + '/' + str(up_to))\n",
    "        name = 'cell_' + str(i)\n",
    "\n",
    "        #print(str2array(df_shuffled['pcna_crops'][i])*255)\n",
    "\n",
    "        try:\n",
    "            arr = str2array(df_shuffled['pcna_crops'][i])*255\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        if arr.dtype is np.dtype('object'):\n",
    "            continue\n",
    "\n",
    "\n",
    "        if df_shuffled['ground_truth'][i] == ['g1_phase']:\n",
    "            path = 'C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\training_data\\\\g1_phase\\\\' + name + '.png'\n",
    "            #arr = str2array(df_shuffled['pcna_crops'][i])\n",
    "            im = Image.fromarray(arr)\n",
    "            im = im.convert(\"L\")\n",
    "            im.save(path)\n",
    "\n",
    "        elif df_shuffled['ground_truth'][i] == ['s_phase']:\n",
    "            path = 'C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\training_data\\\\s_phase\\\\' + name + '.png'\n",
    "            #arr = str2array(df_shuffled['pcna_crops'][i])\n",
    "            im = Image.fromarray(arr)\n",
    "            im = im.convert(\"L\")\n",
    "            im.save(path)\n",
    "\n",
    "        elif df_shuffled['ground_truth'][i] == ['g2_m_phase']:\n",
    "            path = 'C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\training_data\\\\g2_m_phase\\\\' + name + '.png'\n",
    "            #arr = str2array(df_shuffled['pcna_crops'][i])\n",
    "            im = Image.fromarray(arr)\n",
    "            im = im.convert(\"L\")\n",
    "            im.save(path)\n",
    "\n",
    "    #do the same for the testing data\n",
    "    for i in range(up_to,total_images):\n",
    "        if i % 1000 == 0: print(str(i+1) + '/' + str(total_images))\n",
    "\n",
    "        try:\n",
    "            arr = str2array(df_shuffled['pcna_crops'][i])*255\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        if arr.dtype is np.dtype('object'):\n",
    "            continue\n",
    "\n",
    "        name = 'cell_' + str(i)\n",
    "        if df_shuffled['ground_truth'][i] == ['g1_phase']:\n",
    "            path = 'C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\testing_data\\\\g1_phase\\\\' + name + '.png'\n",
    "            #arr = str2array(df_shuffled['pcna_crops'][i])\n",
    "            im = Image.fromarray(arr)\n",
    "            im = im.convert(\"L\")\n",
    "            im.save(path)\n",
    "\n",
    "        elif df_shuffled['ground_truth'][i] == ['s_phase']:\n",
    "            path = 'C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\testing_data\\\\s_phase\\\\' + name + '.png'\n",
    "            #arr = str2array(df_shuffled['pcna_crops'][i])\n",
    "            im = Image.fromarray(arr)\n",
    "            im = im.convert(\"L\")\n",
    "            im.save(path)\n",
    "\n",
    "        elif df_shuffled['ground_truth'][i] == ['g2_m_phase']:\n",
    "            path = 'C:\\\\Users\\\\rz200\\\\Documents\\\\development\\\\cell-SCT\\\\classification\\\\data\\\\testing_data\\\\g2_m_phase\\\\' + name + '.png'\n",
    "            #arr = str2array(df_shuffled['pcna_crops'][i])\n",
    "            im = Image.fromarray(arr)\n",
    "            im = im.convert(\"L\")\n",
    "            im.save(path)\n",
    "\n",
    "    #no need to return anything\n",
    "\n",
    "sort_training_and_testing_data(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [],
   "source": [
    "import io\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CellImagesDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(csv_file)\n",
    "        indices_to_skip_img_wrong_shape = [i for i in range(len(df)) if\n",
    "                                           str2array(df['dapi_crops'][i]).dtype is np.dtype(\n",
    "                                               'object')]  # skipping rows with shapes such as (7,)\n",
    "        indices_to_skip_img_wrong_shape = [i for i in range(len(df)) if\n",
    "                                           str2array(df['cyclina2_crops'][i]).dtype is np.dtype(\n",
    "                                               'object')]  # skipping rows with shapes such as (7,)\n",
    "        indices_to_skip_img_wrong_shape = [i for i in range(len(df)) if\n",
    "                                           str2array(df['edu_crops'][i]).dtype is np.dtype(\n",
    "                                               'object')]  # skipping rows with shapes such as (7,)\n",
    "        indices_to_skip_img_wrong_shape = [i for i in range(len(df)) if\n",
    "                                           str2array(df['pcna_crops'][i]).dtype is np.dtype(\n",
    "                                               'object')]  # skipping rows with shapes such as (7,)\n",
    "        df = df.drop(indices_to_skip_img_wrong_shape).reset_index(drop=True)\n",
    "\n",
    "        cycle_phase_encodings = []\n",
    "        for i in range(len(df['S_Phase'])):\n",
    "            encoding_arr = []\n",
    "            if df['G1_Phase'][i]: encoding_arr.append('g1_phase')\n",
    "            #else: encoding_arr.append(0)\n",
    "\n",
    "            if df['S_Phase'][i]: encoding_arr.append('s_phase')\n",
    "            #else: encoding_arr.append(0)\n",
    "\n",
    "            if df['G2_M_Phase'][i]: encoding_arr.append('g2_m_phase')\n",
    "            #else: encoding_arr.append(0)\n",
    "\n",
    "            if len(encoding_arr) != 1: encoding_arr = ['unclassified']\n",
    "\n",
    "            cycle_phase_encodings.append(encoding_arr)\n",
    "\n",
    "        df['ground_truth'] = cycle_phase_encodings\n",
    "\n",
    "\n",
    "        self.cells_frame = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cells_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        #I want the image as 4 channels\n",
    "        try:\n",
    "            arr_dapi = str2array(df['dapi_crops'][idx])*255\n",
    "            arr_cyclina2 = str2array(df['cyclina2_crops'][idx])*255\n",
    "            arr_edu = str2array(df['edu_crops'][idx])*255\n",
    "            arr_pcna = str2array(df['pcna_crops'][idx])*255\n",
    "        except TypeError:\n",
    "            pass\n",
    "\n",
    "        arr = np.dstack((arr_dapi,arr_cyclina2,arr_edu,arr_pcna))\n",
    "        image = arr.astype(np.uint8)\n",
    "\n",
    "        #I want the label\n",
    "        label = self.cells_frame['ground_truth'][idx][0]\n",
    "        if label =='g1_phase':label=0\n",
    "        elif label =='s_phase':label=1\n",
    "        elif label=='g2_m_phase':label=2\n",
    "\n",
    "        #I want to return them both as tensors\n",
    "        #image = torch.from_numpy(image)\n",
    "        #print(type(image))\n",
    "        #label = torch.tensor(label)\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        #image, label = sample['image'], sample['label']\n",
    "        #image = torch.tensor(image)\n",
    "        #sample = {'image': img, 'label': label}\n",
    "\n",
    "\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "class CenterCrop(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        image = torchvision.transforms.CenterCrop(self.output_size).forward(image)\n",
    "        return {'image': image, 'label': label}\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.tensor(label)}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rz200\\Documents\\development\\cell-SCT\\classification\\ccc_nn_functions.py:106: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(ast.literal_eval(s))\n"
     ]
    }
   ],
   "source": [
    "transformed_dataset = CellImagesDataset(csv_file=r'C:\\Users\\rz200\\Documents\\development\\cell-SCT\\classification\\imported_CSV\\dataframe_821',\n",
    "                                           root_dir='data/faces/',\n",
    "                                           transform=transforms.Compose([\n",
    "                                               CenterCrop(32),\n",
    "                                               ToTensor()\n",
    "\n",
    "\n",
    "                                           ]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Unexpected type <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [282]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(transformed_dataset)):\n\u001B[1;32m----> 2\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[43mtransformed_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(i, sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msize(), sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n",
      "Input \u001B[1;32mIn [278]\u001B[0m, in \u001B[0;36mCellImagesDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     83\u001B[0m sample \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m: image, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m: label}\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform:\n\u001B[1;32m---> 86\u001B[0m     sample \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;66;03m#image, label = sample['image'], sample['label']\u001B[39;00m\n\u001B[0;32m     89\u001B[0m \u001B[38;5;66;03m#image = torch.tensor(image)\u001B[39;00m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;66;03m#sample = {'image': img, 'label': label}\u001B[39;00m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sample\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "Input \u001B[1;32mIn [279]\u001B[0m, in \u001B[0;36mCenterCrop.__call__\u001B[1;34m(self, sample)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, sample):\n\u001B[0;32m     15\u001B[0m     image, label \u001B[38;5;241m=\u001B[39m sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m], sample[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 16\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCenterCrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_size\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m: image, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m: label}\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torchvision\\transforms\\transforms.py:381\u001B[0m, in \u001B[0;36mCenterCrop.forward\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m    374\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    375\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;124;03m        img (PIL Image or Tensor): Image to be cropped.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    379\u001B[0m \u001B[38;5;124;03m        PIL Image or Tensor: Cropped image.\u001B[39;00m\n\u001B[0;32m    380\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 381\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcenter_crop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torchvision\\transforms\\functional.py:536\u001B[0m, in \u001B[0;36mcenter_crop\u001B[1;34m(img, output_size)\u001B[0m\n\u001B[0;32m    533\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(output_size, (\u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mlist\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(output_size) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    534\u001B[0m     output_size \u001B[38;5;241m=\u001B[39m (output_size[\u001B[38;5;241m0\u001B[39m], output_size[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m--> 536\u001B[0m image_width, image_height \u001B[38;5;241m=\u001B[39m \u001B[43mget_image_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    537\u001B[0m crop_height, crop_width \u001B[38;5;241m=\u001B[39m output_size\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m crop_width \u001B[38;5;241m>\u001B[39m image_width \u001B[38;5;129;01mor\u001B[39;00m crop_height \u001B[38;5;241m>\u001B[39m image_height:\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torchvision\\transforms\\functional.py:76\u001B[0m, in \u001B[0;36mget_image_size\u001B[1;34m(img)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F_t\u001B[38;5;241m.\u001B[39mget_image_size(img)\n\u001B[1;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF_pil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_image_size\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:27\u001B[0m, in \u001B[0;36mget_image_size\u001B[1;34m(img)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_pil_image(img):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(img\u001B[38;5;241m.\u001B[39msize)\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(img)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: Unexpected type <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].size(), sample['label'].size())\n",
    "\n",
    "    if i == 3:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "\n",
    "    print(i,sample['label'])\n",
    "\n",
    "    if i == 1000:break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (4, 32, 32) for image data",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [277]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformed_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001B[0m, in \u001B[0;36mmake_keyword_only.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m name_idx:\n\u001B[0;32m    454\u001B[0m     warn_deprecated(\n\u001B[0;32m    455\u001B[0m         since, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing the \u001B[39m\u001B[38;5;132;01m%(name)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%(obj_type)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    456\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositionally is deprecated since Matplotlib \u001B[39m\u001B[38;5;132;01m%(since)s\u001B[39;00m\u001B[38;5;124m; the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    457\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter will become keyword-only \u001B[39m\u001B[38;5;132;01m%(removal)s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    458\u001B[0m         name\u001B[38;5;241m=\u001B[39mname, obj_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\matplotlib\\pyplot.py:2652\u001B[0m, in \u001B[0;36mimshow\u001B[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[0;32m   2646\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[0;32m   2647\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[0;32m   2648\u001B[0m         X, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, aspect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, interpolation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   2649\u001B[0m         alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, vmax\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, origin\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, extent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   2650\u001B[0m         interpolation_stage\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, filternorm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, filterrad\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4.0\u001B[39m,\n\u001B[0;32m   2651\u001B[0m         resample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, url\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m-> 2652\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m \u001B[43mgca\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimshow\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2653\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcmap\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcmap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maspect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maspect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2654\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmin\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2655\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvmax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvmax\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morigin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morigin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2656\u001B[0m \u001B[43m        \u001B[49m\u001B[43minterpolation_stage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minterpolation_stage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2657\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilternorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilternorm\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilterrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilterrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2658\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m}\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2659\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2660\u001B[0m     sci(__ret)\n\u001B[0;32m   2661\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001B[0m, in \u001B[0;36mmake_keyword_only.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m name_idx:\n\u001B[0;32m    454\u001B[0m     warn_deprecated(\n\u001B[0;32m    455\u001B[0m         since, message\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPassing the \u001B[39m\u001B[38;5;132;01m%(name)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m%(obj_type)s\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    456\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpositionally is deprecated since Matplotlib \u001B[39m\u001B[38;5;132;01m%(since)s\u001B[39;00m\u001B[38;5;124m; the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    457\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter will become keyword-only \u001B[39m\u001B[38;5;132;01m%(removal)s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    458\u001B[0m         name\u001B[38;5;241m=\u001B[39mname, obj_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1409\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1410\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1411\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1412\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43max\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mmap\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msanitize_sequence\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1414\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1415\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1416\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5481\u001B[0m, in \u001B[0;36mAxes.imshow\u001B[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[0m\n\u001B[0;32m   5474\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_aspect(aspect)\n\u001B[0;32m   5475\u001B[0m im \u001B[38;5;241m=\u001B[39m mimage\u001B[38;5;241m.\u001B[39mAxesImage(\u001B[38;5;28mself\u001B[39m, cmap, norm, interpolation,\n\u001B[0;32m   5476\u001B[0m                       origin, extent, filternorm\u001B[38;5;241m=\u001B[39mfilternorm,\n\u001B[0;32m   5477\u001B[0m                       filterrad\u001B[38;5;241m=\u001B[39mfilterrad, resample\u001B[38;5;241m=\u001B[39mresample,\n\u001B[0;32m   5478\u001B[0m                       interpolation_stage\u001B[38;5;241m=\u001B[39minterpolation_stage,\n\u001B[0;32m   5479\u001B[0m                       \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 5481\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5482\u001B[0m im\u001B[38;5;241m.\u001B[39mset_alpha(alpha)\n\u001B[0;32m   5483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5484\u001B[0m     \u001B[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\matplotlib\\image.py:715\u001B[0m, in \u001B[0;36m_ImageBase.set_data\u001B[1;34m(self, A)\u001B[0m\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A[:, :, \u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    714\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m]):\n\u001B[1;32m--> 715\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid shape \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m for image data\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    716\u001B[0m                     \u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mshape))\n\u001B[0;32m    718\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m    719\u001B[0m     \u001B[38;5;66;03m# If the input data has values outside the valid range (after\u001B[39;00m\n\u001B[0;32m    720\u001B[0m     \u001B[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001B[39;00m\n\u001B[0;32m    721\u001B[0m     \u001B[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001B[39;00m\n\u001B[0;32m    722\u001B[0m     \u001B[38;5;66;03m# making reliable interpretation impossible.\u001B[39;00m\n\u001B[0;32m    723\u001B[0m     high \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39minteger) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: Invalid shape (4, 32, 32) for image data"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(transformed_dataset[30]['image'])\n",
    "#The images are all 0s, again"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms\n",
    "\n",
    "#datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root = r'C:\\Users\\rz200\\Documents\\development\\cell-SCT\\classification\\data\\training_data',\n",
    "                                     transform = transforms.Compose([\n",
    "                                         transforms.Grayscale(),\n",
    "                                         transforms.Resize((32,32)),\n",
    "                                         transforms.RandomRotation(degrees=(0,180)),\n",
    "                                         transforms.ToTensor()]))\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root = r'C:\\Users\\rz200\\Documents\\development\\cell-SCT\\classification\\data\\testing_data',\n",
    "                                          transform = transforms.Compose([\n",
    "                                              transforms.Grayscale(),\n",
    "                                              transforms.Resize((32,32)),\n",
    "                                              transforms.ToTensor()]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "model = LeNet5(num_classes).to(device)\n",
    "\n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [1/1599], Loss: 1.0549\n",
      "Epoch [1/10], Step [101/1599], Loss: 0.7847\n",
      "Epoch [1/10], Step [201/1599], Loss: 0.7740\n",
      "Epoch [1/10], Step [301/1599], Loss: 0.7492\n",
      "Epoch [1/10], Step [401/1599], Loss: 1.0579\n",
      "Epoch [1/10], Step [501/1599], Loss: 0.9992\n",
      "Epoch [1/10], Step [601/1599], Loss: 0.8333\n",
      "Epoch [1/10], Step [701/1599], Loss: 0.5624\n",
      "Epoch [1/10], Step [801/1599], Loss: 0.6702\n",
      "Epoch [1/10], Step [901/1599], Loss: 0.8267\n",
      "Epoch [1/10], Step [1001/1599], Loss: 0.8117\n",
      "Epoch [1/10], Step [1101/1599], Loss: 0.7598\n",
      "Epoch [1/10], Step [1201/1599], Loss: 0.6814\n",
      "Epoch [1/10], Step [1301/1599], Loss: 0.7053\n",
      "Epoch [1/10], Step [1401/1599], Loss: 0.8633\n",
      "Epoch [1/10], Step [1501/1599], Loss: 0.8915\n",
      "Epoch [1/10], Step [1599/1599], Loss: 0.7200\n",
      "Epoch [2/10], Step [1/1599], Loss: 0.7781\n",
      "Epoch [2/10], Step [101/1599], Loss: 0.7001\n",
      "Epoch [2/10], Step [201/1599], Loss: 0.7558\n",
      "Epoch [2/10], Step [301/1599], Loss: 0.7439\n",
      "Epoch [2/10], Step [401/1599], Loss: 0.8187\n",
      "Epoch [2/10], Step [501/1599], Loss: 0.7293\n",
      "Epoch [2/10], Step [601/1599], Loss: 0.6359\n",
      "Epoch [2/10], Step [701/1599], Loss: 0.8554\n",
      "Epoch [2/10], Step [801/1599], Loss: 0.6652\n",
      "Epoch [2/10], Step [901/1599], Loss: 0.7356\n",
      "Epoch [2/10], Step [1001/1599], Loss: 0.7822\n",
      "Epoch [2/10], Step [1101/1599], Loss: 0.8087\n",
      "Epoch [2/10], Step [1201/1599], Loss: 0.7181\n",
      "Epoch [2/10], Step [1301/1599], Loss: 0.5501\n",
      "Epoch [2/10], Step [1401/1599], Loss: 0.8297\n",
      "Epoch [2/10], Step [1501/1599], Loss: 0.7560\n",
      "Epoch [2/10], Step [1599/1599], Loss: 0.6849\n",
      "Epoch [3/10], Step [1/1599], Loss: 0.6784\n",
      "Epoch [3/10], Step [101/1599], Loss: 0.7583\n",
      "Epoch [3/10], Step [201/1599], Loss: 0.8480\n",
      "Epoch [3/10], Step [301/1599], Loss: 0.6968\n",
      "Epoch [3/10], Step [401/1599], Loss: 0.7850\n",
      "Epoch [3/10], Step [501/1599], Loss: 0.8588\n",
      "Epoch [3/10], Step [601/1599], Loss: 0.6810\n",
      "Epoch [3/10], Step [701/1599], Loss: 0.6511\n",
      "Epoch [3/10], Step [801/1599], Loss: 0.7403\n",
      "Epoch [3/10], Step [901/1599], Loss: 0.9212\n",
      "Epoch [3/10], Step [1001/1599], Loss: 0.7178\n",
      "Epoch [3/10], Step [1101/1599], Loss: 0.7179\n",
      "Epoch [3/10], Step [1201/1599], Loss: 0.8276\n",
      "Epoch [3/10], Step [1301/1599], Loss: 0.7421\n",
      "Epoch [3/10], Step [1401/1599], Loss: 0.7264\n",
      "Epoch [3/10], Step [1501/1599], Loss: 0.7686\n",
      "Epoch [3/10], Step [1599/1599], Loss: 0.7639\n",
      "Epoch [4/10], Step [1/1599], Loss: 0.5573\n",
      "Epoch [4/10], Step [101/1599], Loss: 0.7168\n",
      "Epoch [4/10], Step [201/1599], Loss: 0.7809\n",
      "Epoch [4/10], Step [301/1599], Loss: 0.6665\n",
      "Epoch [4/10], Step [401/1599], Loss: 0.6451\n",
      "Epoch [4/10], Step [501/1599], Loss: 0.7585\n",
      "Epoch [4/10], Step [601/1599], Loss: 0.5574\n",
      "Epoch [4/10], Step [701/1599], Loss: 0.7947\n",
      "Epoch [4/10], Step [801/1599], Loss: 0.7614\n",
      "Epoch [4/10], Step [901/1599], Loss: 0.7564\n",
      "Epoch [4/10], Step [1001/1599], Loss: 0.6383\n",
      "Epoch [4/10], Step [1101/1599], Loss: 0.8383\n",
      "Epoch [4/10], Step [1201/1599], Loss: 0.7635\n",
      "Epoch [4/10], Step [1301/1599], Loss: 0.7270\n",
      "Epoch [4/10], Step [1401/1599], Loss: 0.6674\n",
      "Epoch [4/10], Step [1501/1599], Loss: 0.8370\n",
      "Epoch [4/10], Step [1599/1599], Loss: 0.8463\n",
      "Epoch [5/10], Step [1/1599], Loss: 0.7093\n",
      "Epoch [5/10], Step [101/1599], Loss: 0.6669\n",
      "Epoch [5/10], Step [201/1599], Loss: 0.6246\n",
      "Epoch [5/10], Step [301/1599], Loss: 0.8517\n",
      "Epoch [5/10], Step [401/1599], Loss: 0.6601\n",
      "Epoch [5/10], Step [501/1599], Loss: 0.7872\n",
      "Epoch [5/10], Step [601/1599], Loss: 0.8287\n",
      "Epoch [5/10], Step [701/1599], Loss: 0.7333\n",
      "Epoch [5/10], Step [801/1599], Loss: 0.6160\n",
      "Epoch [5/10], Step [901/1599], Loss: 0.7602\n",
      "Epoch [5/10], Step [1001/1599], Loss: 0.6332\n",
      "Epoch [5/10], Step [1101/1599], Loss: 0.7556\n",
      "Epoch [5/10], Step [1201/1599], Loss: 0.7716\n",
      "Epoch [5/10], Step [1301/1599], Loss: 0.8057\n",
      "Epoch [5/10], Step [1401/1599], Loss: 0.6901\n",
      "Epoch [5/10], Step [1501/1599], Loss: 0.9132\n",
      "Epoch [5/10], Step [1599/1599], Loss: 0.5936\n",
      "Epoch [6/10], Step [1/1599], Loss: 0.7027\n",
      "Epoch [6/10], Step [101/1599], Loss: 0.7529\n",
      "Epoch [6/10], Step [201/1599], Loss: 0.4749\n",
      "Epoch [6/10], Step [301/1599], Loss: 0.6935\n",
      "Epoch [6/10], Step [401/1599], Loss: 0.7159\n",
      "Epoch [6/10], Step [501/1599], Loss: 0.7657\n",
      "Epoch [6/10], Step [601/1599], Loss: 0.7324\n",
      "Epoch [6/10], Step [701/1599], Loss: 0.5049\n",
      "Epoch [6/10], Step [801/1599], Loss: 0.6924\n",
      "Epoch [6/10], Step [901/1599], Loss: 0.7626\n",
      "Epoch [6/10], Step [1001/1599], Loss: 0.6220\n",
      "Epoch [6/10], Step [1101/1599], Loss: 0.7370\n",
      "Epoch [6/10], Step [1201/1599], Loss: 0.8605\n",
      "Epoch [6/10], Step [1301/1599], Loss: 0.7201\n",
      "Epoch [6/10], Step [1401/1599], Loss: 0.6466\n",
      "Epoch [6/10], Step [1501/1599], Loss: 0.7733\n",
      "Epoch [6/10], Step [1599/1599], Loss: 0.8859\n",
      "Epoch [7/10], Step [1/1599], Loss: 0.7474\n",
      "Epoch [7/10], Step [101/1599], Loss: 0.7357\n",
      "Epoch [7/10], Step [201/1599], Loss: 0.7789\n",
      "Epoch [7/10], Step [301/1599], Loss: 0.6479\n",
      "Epoch [7/10], Step [401/1599], Loss: 0.9152\n",
      "Epoch [7/10], Step [501/1599], Loss: 0.6979\n",
      "Epoch [7/10], Step [601/1599], Loss: 0.6653\n",
      "Epoch [7/10], Step [701/1599], Loss: 0.7616\n",
      "Epoch [7/10], Step [801/1599], Loss: 0.7043\n",
      "Epoch [7/10], Step [901/1599], Loss: 0.6871\n",
      "Epoch [7/10], Step [1001/1599], Loss: 0.8057\n",
      "Epoch [7/10], Step [1101/1599], Loss: 0.9005\n",
      "Epoch [7/10], Step [1201/1599], Loss: 0.5721\n",
      "Epoch [7/10], Step [1301/1599], Loss: 0.6917\n",
      "Epoch [7/10], Step [1401/1599], Loss: 0.6957\n",
      "Epoch [7/10], Step [1501/1599], Loss: 0.6611\n",
      "Epoch [7/10], Step [1599/1599], Loss: 1.1142\n",
      "Epoch [8/10], Step [1/1599], Loss: 0.8134\n",
      "Epoch [8/10], Step [101/1599], Loss: 0.6273\n",
      "Epoch [8/10], Step [201/1599], Loss: 0.7786\n",
      "Epoch [8/10], Step [301/1599], Loss: 0.6739\n",
      "Epoch [8/10], Step [401/1599], Loss: 0.7522\n",
      "Epoch [8/10], Step [501/1599], Loss: 0.7462\n",
      "Epoch [8/10], Step [601/1599], Loss: 0.7529\n",
      "Epoch [8/10], Step [701/1599], Loss: 0.8399\n",
      "Epoch [8/10], Step [801/1599], Loss: 0.7857\n",
      "Epoch [8/10], Step [901/1599], Loss: 0.7142\n",
      "Epoch [8/10], Step [1001/1599], Loss: 0.6246\n",
      "Epoch [8/10], Step [1101/1599], Loss: 0.7894\n",
      "Epoch [8/10], Step [1201/1599], Loss: 0.8039\n",
      "Epoch [8/10], Step [1301/1599], Loss: 0.7903\n",
      "Epoch [8/10], Step [1401/1599], Loss: 0.8141\n",
      "Epoch [8/10], Step [1501/1599], Loss: 0.4751\n",
      "Epoch [8/10], Step [1599/1599], Loss: 0.5882\n",
      "Epoch [9/10], Step [1/1599], Loss: 0.8422\n",
      "Epoch [9/10], Step [101/1599], Loss: 0.5564\n",
      "Epoch [9/10], Step [201/1599], Loss: 0.6976\n",
      "Epoch [9/10], Step [301/1599], Loss: 0.7766\n",
      "Epoch [9/10], Step [401/1599], Loss: 0.6457\n",
      "Epoch [9/10], Step [501/1599], Loss: 0.5876\n",
      "Epoch [9/10], Step [601/1599], Loss: 0.8001\n",
      "Epoch [9/10], Step [701/1599], Loss: 0.7930\n",
      "Epoch [9/10], Step [801/1599], Loss: 0.6499\n",
      "Epoch [9/10], Step [901/1599], Loss: 0.7105\n",
      "Epoch [9/10], Step [1001/1599], Loss: 0.6879\n",
      "Epoch [9/10], Step [1101/1599], Loss: 0.5918\n",
      "Epoch [9/10], Step [1201/1599], Loss: 0.4846\n",
      "Epoch [9/10], Step [1301/1599], Loss: 0.6625\n",
      "Epoch [9/10], Step [1401/1599], Loss: 0.6847\n",
      "Epoch [9/10], Step [1501/1599], Loss: 0.6547\n",
      "Epoch [9/10], Step [1599/1599], Loss: 0.6945\n",
      "Epoch [10/10], Step [1/1599], Loss: 0.9870\n",
      "Epoch [10/10], Step [101/1599], Loss: 0.7758\n",
      "Epoch [10/10], Step [201/1599], Loss: 0.7491\n",
      "Epoch [10/10], Step [301/1599], Loss: 0.6018\n",
      "Epoch [10/10], Step [401/1599], Loss: 0.8357\n",
      "Epoch [10/10], Step [501/1599], Loss: 0.5662\n",
      "Epoch [10/10], Step [601/1599], Loss: 0.7935\n",
      "Epoch [10/10], Step [701/1599], Loss: 0.7259\n",
      "Epoch [10/10], Step [801/1599], Loss: 0.7446\n",
      "Epoch [10/10], Step [901/1599], Loss: 0.8190\n",
      "Epoch [10/10], Step [1001/1599], Loss: 0.6502\n",
      "Epoch [10/10], Step [1101/1599], Loss: 0.6777\n",
      "Epoch [10/10], Step [1201/1599], Loss: 0.6070\n",
      "Epoch [10/10], Step [1301/1599], Loss: 0.6874\n",
      "Epoch [10/10], Step [1401/1599], Loss: 0.7337\n",
      "Epoch [10/10], Step [1501/1599], Loss: 0.7803\n",
      "Epoch [10/10], Step [1599/1599], Loss: 0.6010\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "#should add a progress bar to this\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    losses_per_epoch = []\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0: print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        if (i+1) == total_step: print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "\n",
    "        losses_per_epoch.append(loss.item())\n",
    "    losses.append(sum(losses_per_epoch)/len(losses_per_epoch))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss per epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(losses)\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 400 test images: 65.25529752130737 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the {} test images: {} %'.format(len(test_loader), 100 * correct / total))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#I think the image are all 0s because they are normalised from 0 to 1\n",
    "#At some point they get rounded (maybe when put as pngs) which makes them all 0s, so fully blank images\n",
    "#We need to either not normalise them before we store them, or denormalise them by multiplying by 255\n",
    "#This would explain why it was stuck at 67%? No since if it was random, it would be a 33% accuracy\n",
    "\n",
    "#Need to add some augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}