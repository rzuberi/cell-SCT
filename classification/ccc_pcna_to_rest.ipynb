{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, I want to see if from the PCNA values, a model can output the DAPI, Cyclin A2 and EdU values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#I think we would want to go from the PCNA crop to guess the average DAPI value\n",
    "\n",
    "#Let's get the PCNA numpys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ccc_nn_functions import str2array\n",
    "\n",
    "csv_file = r'C:\\Users\\rz200\\Documents\\development\\cell-SCT\\classification\\imported_CSV\\dataframe_821'\n",
    "df = pd.read_csv(csv_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rz200\\Documents\\development\\cell-SCT\\classification\\ccc_nn_functions.py:106: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(ast.literal_eval(s))\n"
     ]
    }
   ],
   "source": [
    "def df_ignore_rows(df):\n",
    "    indices_to_skip_img_wrong_shape = [i for i in range(len(df)) if str2array(df['pcna_crops'][i]).dtype is np.dtype('object')]  # skipping rows with shapes such as (7,)\n",
    "    indices_to_skip_no_class = df[(df['G1_Phase'] == False) & (df['S_Phase'] == False) & (df['G2_M_Phase'] == False)].index\n",
    "\n",
    "    rows_to_ignore = np.concatenate((indices_to_skip_img_wrong_shape, indices_to_skip_no_class), axis=0)\n",
    "    df = df.drop(set(rows_to_ignore)).reset_index(drop=True) #dropping the rows to ignore\n",
    "\n",
    "    return df\n",
    "\n",
    "df = df_ignore_rows(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 21>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m     pcna_crops_flat_pad \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(pcna_crops_flat_pad)\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pcna_crops_flat_pad\n\u001B[1;32m---> 21\u001B[0m pcna_crops_flat_pad \u001B[38;5;241m=\u001B[39m \u001B[43mget_pcna_crops_flat_pad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36mget_pcna_crops_flat_pad\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_pcna_crops_flat_pad\u001B[39m(df):\n\u001B[0;32m      2\u001B[0m     pcna_crops \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(df)): pcna_crops\u001B[38;5;241m.\u001B[39mappend(\u001B[43mstr2array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpcna_crops\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m#We'll want to flatten all of these arrays\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     pcna_crops_flat \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\Documents\\development\\cell-SCT\\classification\\ccc_nn_functions.py:105\u001B[0m, in \u001B[0;36mstr2array\u001B[1;34m(s)\u001B[0m\n\u001B[0;32m    103\u001B[0m s \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m[ +\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m[\u001B[39m\u001B[38;5;124m'\u001B[39m, s\u001B[38;5;241m.\u001B[39mstrip())\n\u001B[0;32m    104\u001B[0m \u001B[38;5;66;03m# Replace commas and spaces\u001B[39;00m\n\u001B[1;32m--> 105\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[43mre\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m[,\u001B[39;49m\u001B[38;5;124;43m\\\u001B[39;49m\u001B[38;5;124;43ms]+\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m, \u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(ast\u001B[38;5;241m.\u001B[39mliteral_eval(s))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def get_pcna_crops_flat_pad(df):\n",
    "    pcna_crops = []\n",
    "    for i in range(len(df)): pcna_crops.append(str2array(df['pcna_crops'][i]))\n",
    "    #We'll want to flatten all of these arrays\n",
    "    pcna_crops_flat = []\n",
    "    for i in range(len(pcna_crops)):\n",
    "        pcna_crops_flat.append(pcna_crops[i].flatten())\n",
    "    #Then we want to get the longest one\n",
    "    max_shape = max([flat_crop.shape[0] for flat_crop in pcna_crops_flat])\n",
    "    #Then we want to add 0s at the end of everyone that isn't as long as the longest one\n",
    "    pcna_crops_flat_pad = []\n",
    "    for i in range(len(pcna_crops_flat)):\n",
    "        A = pcna_crops_flat[i]\n",
    "        pad_size = max_shape - A.shape[0]\n",
    "        new_arr = np.pad(A, (0, pad_size), 'constant')\n",
    "        pcna_crops_flat_pad.append(new_arr)\n",
    "    pcna_crops_flat_pad = np.array(pcna_crops_flat_pad)\n",
    "\n",
    "    return pcna_crops_flat_pad\n",
    "\n",
    "pcna_crops_flat_pad = get_pcna_crops_flat_pad(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_label_values(df):\n",
    "    dapi_values = []\n",
    "    cyclina2_values = []\n",
    "    edu_values = []\n",
    "    dna_values = []\n",
    "    pcna_values = []\n",
    "    for i in range(len(df)):\n",
    "        dapi_values.append(df['dapi_values'][i])\n",
    "        cyclina2_values.append(df['cyclina2_values'][i])\n",
    "        edu_values.append(df['edu_values'][i])\n",
    "        dna_values.append(df['DNA_content'][i])\n",
    "        pcna_values.append(df['pcna_values'][i])\n",
    "    dapi_values = np.array(dapi_values)\n",
    "    cyclina2_values = np.array(cyclina2_values)\n",
    "    edu_values = np.array(edu_values)\n",
    "    dna_values = np.array(dna_values)\n",
    "    pcna_values = np.array(pcna_values)\n",
    "\n",
    "    return dapi_values,cyclina2_values,edu_values,dna_values, pcna_values\n",
    "\n",
    "dapi_values, cyclina2_values, edu_values, dna_values, pcna_values = get_label_values(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statistics import mean\n",
    "\n",
    "def off_score(model,X,y):\n",
    "    predictions = model.predict(X)\n",
    "    result = abs(predictions - y)\n",
    "    return mean(result)\n",
    "\n",
    "def off_perc(model,X,y):\n",
    "    predictions = model.predict(X)\n",
    "    result = abs(predictions - y)\n",
    "    percentage_off = []\n",
    "    for i in range(len(predictions)):\n",
    "        percentage_off.append(result[i]*100/y[i])\n",
    "    mean_perc = mean(percentage_off)\n",
    "    return 100 - mean_perc\n",
    "\n",
    "def get_reg_model(images,values):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, values, test_size=0.5, random_state=42)\n",
    "    reg = LinearRegression().fit(X_train,y_train)\n",
    "    print('Off score:',off_score(reg,X_test,y_test),'|','Accuracy:',str(round(off_perc(reg,X_test,y_test),2)) + '%')\n",
    "    return reg\n",
    "\n",
    "dapi_mod = get_reg_model(pcna_crops_flat_pad,dapi_values)\n",
    "cyclina2_mod = get_reg_model(pcna_crops_flat_pad,cyclina2_values)\n",
    "edu_mod = get_reg_model(pcna_crops_flat_pad,edu_values)\n",
    "dna_mod = get_reg_model(pcna_crops_flat_pad,dna_values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Need to make a column with the label of the cells\n",
    "\n",
    "def get_cell_labels(df):\n",
    "    g1_indices = df[(df['G1_Phase'] == True)].index\n",
    "    s_indices = df[(df['S_Phase'] == True)].index\n",
    "    g2_m_indices = df[(df['G2_M_Phase'] == True)].index\n",
    "\n",
    "    #make an array that is the length of all of these indices put into one, that is made of 0s\n",
    "    #replace the 0s accordingly by which phase index they correspond to\n",
    "\n",
    "    cell_labels = np.arange(len(g1_indices)+len(s_indices)+len(g2_m_indices))\n",
    "\n",
    "    np.put(cell_labels,g1_indices,np.zeros(len(g1_indices)))\n",
    "    np.put(cell_labels,s_indices,np.ones(len(s_indices)))\n",
    "    np.put(cell_labels,g2_m_indices,np.full(len(g2_m_indices),2))\n",
    "\n",
    "    return cell_labels\n",
    "\n",
    "cell_labels = get_cell_labels(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Make a neural network\n",
    "\n",
    "#Let's get the X data which is the DAPI, Cyclin A2 etc. values\n",
    "#Since we use the same random state (42) it should be the same train and test models\n",
    "#I'll reduce the train size to have more testing data points\n",
    "#This is because we will use these test data points to make values predictions (DAPI etc.)\n",
    "#And these predictions will be part of the training for the neural network\n",
    "#This is because we are making this mega model that starts from PCNA to predict these values that will be used to predict the label\n",
    "#So the X data in this cell will be the value predictiosn (DAPI etc) that we'll generate from the testing data, then we'll split these values with the y being the cell_labels we just got from the cell above\n",
    "#Then we'll put these in a neural network"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [],
   "source": [
    "cell_labels = get_cell_labels(df)\n",
    "\n",
    "def get_value_predictions(X_test, models, pcna_values):\n",
    "    all_preds = []\n",
    "    for model in models:\n",
    "        all_preds.append(model.predict(X_test))\n",
    "\n",
    "    value_predictions = pcna_values\n",
    "    for i in range(len(all_preds)):\n",
    "        value_predictions = np.dstack((value_predictions,all_preds[i]))\n",
    "\n",
    "    value_predictions = np.squeeze(value_predictions)\n",
    "    return value_predictions\n",
    "\n",
    "#really this is a split just to get the correct X_test\n",
    "#we're redoing an X_test right after this with the same random_state just to get the values_predictions as the X\n",
    "cell_labels = get_cell_labels(df)\n",
    "indices = np.arange(len(pcna_crops_flat_pad))\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(pcna_crops_flat_pad, cell_labels, indices, test_size=0.5, random_state=42, shuffle=False)\n",
    "pcna_values_del = np.delete(pcna_values, indices_train)\n",
    "values_predictions = get_value_predictions(X_test,[dapi_mod,cyclina2_mod,edu_mod,dna_mod],pcna_values_del)\n",
    "\n",
    "cell_labels = np.delete(cell_labels,indices_train) #dropping the training data points\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(values_predictions, cell_labels, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#Let's make a mlp classifier that classifies using the real values of each DAPI and all\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m#Then we'll decrease and observe by how much it changes\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m X \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdstack((\u001B[43mget_label_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m)\u001B[49m))\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[0;32m      5\u001B[0m y \u001B[38;5;241m=\u001B[39m get_cell_labels(df)\n\u001B[0;32m      6\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36mget_label_values\u001B[1;34m(df)\u001B[0m\n\u001B[0;32m     10\u001B[0m     edu_values\u001B[38;5;241m.\u001B[39mappend(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medu_values\u001B[39m\u001B[38;5;124m'\u001B[39m][i])\n\u001B[0;32m     11\u001B[0m     dna_values\u001B[38;5;241m.\u001B[39mappend(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDNA_content\u001B[39m\u001B[38;5;124m'\u001B[39m][i])\n\u001B[1;32m---> 12\u001B[0m     pcna_values\u001B[38;5;241m.\u001B[39mappend(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpcna_values\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m     13\u001B[0m dapi_values \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(dapi_values)\n\u001B[0;32m     14\u001B[0m cyclina2_values \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(cyclina2_values)\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\core\\series.py:958\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    955\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m    957\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m--> 958\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_hashable(key):\n\u001B[0;32m    961\u001B[0m     \u001B[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001B[39;00m\n\u001B[0;32m    962\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    963\u001B[0m         \u001B[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\core\\series.py:1069\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1066\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[0;32m   1068\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[1;32m-> 1069\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1070\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_get_values_for_loc(\u001B[38;5;28mself\u001B[39m, loc, label)\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\pandas\\core\\indexes\\range.py:385\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[1;34m(self, key, method, tolerance)\u001B[0m\n\u001B[0;32m    383\u001B[0m new_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(key)\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 385\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_range\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m(new_key)\n\u001B[0;32m    386\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    387\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#Let's make a mlp classifier that classifies using the real values of each DAPI and all\n",
    "#Then we'll decrease and observe by how much it changes\n",
    "\n",
    "X = np.dstack((get_label_values(df))).squeeze()\n",
    "y = get_cell_labels(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8135920180889584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rz200\\.conda\\envs\\celldev\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:559: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(20, 4), random_state=1, max_iter=1000)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Accuracy function\n",
    "def class_pred_acc(model,values,gt):\n",
    "    preds = model.predict(values)\n",
    "    return accuracy_score(gt, preds)\n",
    "\n",
    "print(class_pred_acc(clf, X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Using pytorch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.dstack((get_label_values(df))).squeeze()\n",
    "y = get_cell_labels(df)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) #train-test\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.1, stratify=y_trainval, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_class_distribution(obj):\n",
    "    count_dict = {\n",
    "        \"g1\": 0,\n",
    "        \"s\": 0,\n",
    "        \"g2m\": 0\n",
    "    }\n",
    "\n",
    "    for i in obj:\n",
    "        if i == 0:\n",
    "            count_dict['g1'] += 1\n",
    "        elif i == 1:\n",
    "            count_dict['s'] += 1\n",
    "        elif i == 2:\n",
    "            count_dict['g2m'] += 1\n",
    "        else:\n",
    "            print(\"Check classes.\")\n",
    "\n",
    "    return count_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'Class Distribution in Test Set')"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1800x504 with 3 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(25,7))\n",
    "# Train\n",
    "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_train)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[0]).set_title('Class Distribution in Train Set')\n",
    "# Validation\n",
    "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_val)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[1]).set_title('Class Distribution in Val Set')\n",
    "# Test\n",
    "sns.barplot(data = pd.DataFrame.from_dict([get_class_distribution(y_test)]).melt(), x = \"variable\", y=\"value\", hue=\"variable\",  ax=axes[2]).set_title('Class Distribution in Test Set')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import torch\n",
    "\n",
    "\n",
    "class ClassifierDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "val_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "test_dataset = ClassifierDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "target_list = []\n",
    "for _, t in train_dataset:\n",
    "    target_list.append(t)\n",
    "\n",
    "target_list = torch.tensor(target_list)\n",
    "\n",
    "class_count = [i for i in get_class_distribution(y_train).values()]\n",
    "class_weights = 1./torch.tensor(class_count, dtype=torch.float)\n",
    "class_weights_all = class_weights[target_list]\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=class_weights_all,\n",
    "    num_samples=len(class_weights_all),\n",
    "    replacement=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MulticlassClassification(\n",
      "  (layer_1): Linear(in_features=5, out_features=512, bias=True)\n",
      "  (layer_2): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (layer_3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (layer_out): Linear(in_features=64, out_features=3, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (batchnorm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0007\n",
    "NUM_FEATURES = 5\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          sampler=weighted_sampler\n",
    "                          )\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1)\n",
    "\n",
    "class MulticlassClassification(nn.Module):\n",
    "    def __init__(self, num_feature, num_class):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Linear(num_feature, 512)\n",
    "        self.layer_2 = nn.Linear(512, 128)\n",
    "        self.layer_3 = nn.Linear(128, 64)\n",
    "        self.layer_out = nn.Linear(64, num_class)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(512)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer_2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer_3(x)\n",
    "        x = self.batchnorm3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.layer_out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "\n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "\n",
    "    acc = torch.round(acc * 100)\n",
    "\n",
    "    return acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"val\": []\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/300 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "090b2461e8984cbdb993544120b7e74c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Train Loss: 0.32649 | Val Loss: 0.44243 | Train Acc: 80.041| Val Acc: 79.267\n",
      "Epoch 002: | Train Loss: 0.30412 | Val Loss: 0.45078 | Train Acc: 80.713| Val Acc: 78.812\n",
      "Epoch 003: | Train Loss: 0.29974 | Val Loss: 0.45949 | Train Acc: 80.920| Val Acc: 77.824\n",
      "Epoch 004: | Train Loss: 0.29782 | Val Loss: 0.45539 | Train Acc: 80.930| Val Acc: 78.624\n",
      "Epoch 005: | Train Loss: 0.29549 | Val Loss: 0.46164 | Train Acc: 81.092| Val Acc: 78.229\n",
      "Epoch 006: | Train Loss: 0.29425 | Val Loss: 0.46541 | Train Acc: 81.206| Val Acc: 77.883\n",
      "Epoch 007: | Train Loss: 0.28849 | Val Loss: 0.43966 | Train Acc: 81.392| Val Acc: 78.506\n",
      "Epoch 008: | Train Loss: 0.28681 | Val Loss: 0.44731 | Train Acc: 81.362| Val Acc: 78.812\n",
      "Epoch 009: | Train Loss: 0.28734 | Val Loss: 0.43140 | Train Acc: 81.217| Val Acc: 79.158\n",
      "Epoch 010: | Train Loss: 0.28598 | Val Loss: 0.45622 | Train Acc: 81.365| Val Acc: 77.261\n",
      "Epoch 011: | Train Loss: 0.28455 | Val Loss: 0.45966 | Train Acc: 81.498| Val Acc: 77.982\n",
      "Epoch 012: | Train Loss: 0.27997 | Val Loss: 0.44481 | Train Acc: 81.896| Val Acc: 78.664\n",
      "Epoch 013: | Train Loss: 0.28462 | Val Loss: 0.47541 | Train Acc: 81.423| Val Acc: 77.221\n",
      "Epoch 014: | Train Loss: 0.28153 | Val Loss: 0.44484 | Train Acc: 81.581| Val Acc: 78.318\n",
      "Epoch 015: | Train Loss: 0.28175 | Val Loss: 0.48846 | Train Acc: 81.769| Val Acc: 76.322\n",
      "Epoch 016: | Train Loss: 0.27993 | Val Loss: 0.43529 | Train Acc: 81.924| Val Acc: 79.761\n",
      "Epoch 017: | Train Loss: 0.27751 | Val Loss: 0.44034 | Train Acc: 81.920| Val Acc: 79.217\n",
      "Epoch 018: | Train Loss: 0.27897 | Val Loss: 0.46620 | Train Acc: 81.603| Val Acc: 77.715\n",
      "Epoch 019: | Train Loss: 0.28130 | Val Loss: 0.45394 | Train Acc: 81.533| Val Acc: 78.545\n",
      "Epoch 020: | Train Loss: 0.27877 | Val Loss: 0.43121 | Train Acc: 82.058| Val Acc: 79.504\n",
      "Epoch 021: | Train Loss: 0.27567 | Val Loss: 0.50970 | Train Acc: 82.057| Val Acc: 76.174\n",
      "Epoch 022: | Train Loss: 0.27763 | Val Loss: 0.46477 | Train Acc: 81.936| Val Acc: 77.784\n",
      "Epoch 023: | Train Loss: 0.27672 | Val Loss: 0.46410 | Train Acc: 81.936| Val Acc: 77.458\n",
      "Epoch 024: | Train Loss: 0.27644 | Val Loss: 0.47998 | Train Acc: 81.979| Val Acc: 77.330\n",
      "Epoch 025: | Train Loss: 0.27433 | Val Loss: 0.45465 | Train Acc: 81.949| Val Acc: 77.972\n",
      "Epoch 026: | Train Loss: 0.27281 | Val Loss: 0.43241 | Train Acc: 82.249| Val Acc: 79.415\n",
      "Epoch 027: | Train Loss: 0.27913 | Val Loss: 0.42837 | Train Acc: 81.750| Val Acc: 79.454\n",
      "Epoch 028: | Train Loss: 0.27464 | Val Loss: 0.42348 | Train Acc: 82.069| Val Acc: 79.751\n",
      "Epoch 029: | Train Loss: 0.27697 | Val Loss: 0.43986 | Train Acc: 81.689| Val Acc: 78.348\n",
      "Epoch 030: | Train Loss: 0.27545 | Val Loss: 0.45775 | Train Acc: 81.915| Val Acc: 78.170\n",
      "Epoch 031: | Train Loss: 0.27623 | Val Loss: 0.47127 | Train Acc: 81.871| Val Acc: 77.626\n",
      "Epoch 032: | Train Loss: 0.27486 | Val Loss: 0.46363 | Train Acc: 81.951| Val Acc: 77.705\n",
      "Epoch 033: | Train Loss: 0.27004 | Val Loss: 0.43687 | Train Acc: 82.183| Val Acc: 78.792\n",
      "Epoch 034: | Train Loss: 0.27667 | Val Loss: 0.45253 | Train Acc: 81.858| Val Acc: 78.150\n",
      "Epoch 035: | Train Loss: 0.27558 | Val Loss: 0.45034 | Train Acc: 81.910| Val Acc: 78.694\n",
      "Epoch 036: | Train Loss: 0.27394 | Val Loss: 0.45080 | Train Acc: 81.893| Val Acc: 78.239\n",
      "Epoch 037: | Train Loss: 0.27480 | Val Loss: 0.46277 | Train Acc: 81.961| Val Acc: 77.913\n",
      "Epoch 038: | Train Loss: 0.27510 | Val Loss: 0.43298 | Train Acc: 81.961| Val Acc: 79.079\n",
      "Epoch 039: | Train Loss: 0.27545 | Val Loss: 0.45146 | Train Acc: 81.735| Val Acc: 78.476\n",
      "Epoch 040: | Train Loss: 0.27233 | Val Loss: 0.44763 | Train Acc: 82.115| Val Acc: 78.041\n",
      "Epoch 041: | Train Loss: 0.27142 | Val Loss: 0.43771 | Train Acc: 82.216| Val Acc: 78.921\n",
      "Epoch 042: | Train Loss: 0.27702 | Val Loss: 0.44651 | Train Acc: 81.717| Val Acc: 78.941\n",
      "Epoch 043: | Train Loss: 0.27238 | Val Loss: 0.48630 | Train Acc: 82.106| Val Acc: 76.292\n",
      "Epoch 044: | Train Loss: 0.27206 | Val Loss: 0.45979 | Train Acc: 82.146| Val Acc: 78.308\n",
      "Epoch 045: | Train Loss: 0.27311 | Val Loss: 0.42856 | Train Acc: 82.285| Val Acc: 79.454\n",
      "Epoch 046: | Train Loss: 0.27136 | Val Loss: 0.44002 | Train Acc: 82.041| Val Acc: 78.960\n",
      "Epoch 047: | Train Loss: 0.27304 | Val Loss: 0.44195 | Train Acc: 82.226| Val Acc: 78.921\n",
      "Epoch 048: | Train Loss: 0.27075 | Val Loss: 0.45856 | Train Acc: 82.086| Val Acc: 77.863\n",
      "Epoch 049: | Train Loss: 0.27274 | Val Loss: 0.43794 | Train Acc: 82.072| Val Acc: 79.118\n",
      "Epoch 050: | Train Loss: 0.27428 | Val Loss: 0.45056 | Train Acc: 82.032| Val Acc: 78.031\n",
      "Epoch 051: | Train Loss: 0.27306 | Val Loss: 0.44544 | Train Acc: 82.093| Val Acc: 78.812\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [27]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m train_acc \u001B[38;5;241m=\u001B[39m multi_acc(y_train_pred, y_train_batch)\n\u001B[0;32m     19\u001B[0m train_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 20\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m train_epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[0;32m     23\u001B[0m train_epoch_acc \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_acc\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     86\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[1;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torch\\optim\\adam.py:141\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    138\u001B[0m             \u001B[38;5;66;03m# record the step after step update\u001B[39;00m\n\u001B[0;32m    139\u001B[0m             state_steps\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m--> 141\u001B[0m     \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    142\u001B[0m \u001B[43m           \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    143\u001B[0m \u001B[43m           \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    144\u001B[0m \u001B[43m           \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    145\u001B[0m \u001B[43m           \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    146\u001B[0m \u001B[43m           \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    147\u001B[0m \u001B[43m           \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[43m           \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[43m           \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    150\u001B[0m \u001B[43m           \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    151\u001B[0m \u001B[43m           \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[43m           \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m           \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[1;32m~\\.conda\\envs\\celldev\\lib\\site-packages\\torch\\optim\\_functional.py:98\u001B[0m, in \u001B[0;36madam\u001B[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[0;32m     97\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mmul_(beta1)\u001B[38;5;241m.\u001B[39madd_(grad, alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1)\n\u001B[1;32m---> 98\u001B[0m \u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39maddcmul_(grad, grad\u001B[38;5;241m.\u001B[39mconj(), value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta2)\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amsgrad:\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;66;03m# Maintains the maximum of all 2nd moment running avg. till now\u001B[39;00m\n\u001B[0;32m    101\u001B[0m     torch\u001B[38;5;241m.\u001B[39mmaximum(max_exp_avg_sqs[i], exp_avg_sq, out\u001B[38;5;241m=\u001B[39mmax_exp_avg_sqs[i])\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(\"Begin training.\")\n",
    "for e in tqdm(range(1, EPOCHS+1)):\n",
    "\n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_train_pred = model(X_train_batch)\n",
    "\n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "\n",
    "\n",
    "    # VALIDATION\n",
    "    with torch.no_grad():\n",
    "\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "\n",
    "        model.eval()\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "\n",
    "            y_val_pred = model(X_val_batch)\n",
    "\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n              importance_type=None, interaction_constraints='',\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints='()', n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, objective='multi:softprob',\n              predictor='auto', random_state=0, reg_alpha=0, ...)",
      "text/html": "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n              early_stopping_rounds=None, enable_categorical=False,\n              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n              importance_type=None, interaction_constraints=&#x27;&#x27;,\n              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n              n_jobs=0, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trying xgboot classifier\n",
    "import xgboost\n",
    "\n",
    "X = np.dstack((get_label_values(df))).squeeze()\n",
    "y = get_cell_labels(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.01, random_state=42, shuffle=True)\n",
    "\n",
    "xg = xgboost.XGBClassifier()\n",
    "xg.fit(X_train,y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8284584980237154\n"
     ]
    }
   ],
   "source": [
    "#Accuracy function\n",
    "from sklearn.metrics import accuracy_score\n",
    "def class_pred_acc(model,values,gt):\n",
    "    preds = model.predict(values)\n",
    "    return accuracy_score(gt, preds)\n",
    "\n",
    "print(class_pred_acc(xg,X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125221 1265\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Look into if there's more features we can collect on these cells\n",
    "#Could be good for an RFC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Could also make use of the PCNA images with the other data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.26701209 0.07297885 0.21502775 0.08167543 1.07590322]\n",
      " [0.31337756 0.0936574  0.2561175  0.04560653 1.33358816]\n",
      " [0.26285994 0.10235551 0.21741169 0.04931917 1.49632523]\n",
      " ...\n",
      " [0.28314161 0.08428298 0.20223175 0.0636438  1.22602824]\n",
      " [0.26230655 0.10990231 0.22570132 0.08299008 1.61579281]\n",
      " [0.29674985 0.12230165 0.21580757 0.08387676 1.80925236]]\n"
     ]
    }
   ],
   "source": [
    "print(values_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "#Let's train the neural network now\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=10000)\n",
    "clf = clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6489153121244703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Accuracy function\n",
    "def class_pred_acc(model,values,gt):\n",
    "    preds = model.predict(values)\n",
    "    return accuracy_score(gt, preds)\n",
    "\n",
    "print(class_pred_acc(clf, X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6467965340585669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "sgd = make_pipeline(StandardScaler(),SGDClassifier(max_iter=1000, tol=1e-3))\n",
    "sgd = sgd.fit(X_train, y_train)\n",
    "print(class_pred_acc(sgd,X_test,y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "outputs": [],
   "source": [
    "cell_labels = get_cell_labels(df)\n",
    "indices = np.arange(len(pcna_crops_flat_pad))\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(pcna_crops_flat_pad, cell_labels, indices, test_size=0.5, random_state=42, shuffle=False)\n",
    "pcna_values_del = np.delete(pcna_values, indices_train)\n",
    "values_predictions = get_value_predictions(X_test,[dapi_mod,cyclina2_mod,edu_mod,dna_mod],pcna_values_del)\n",
    "\n",
    "cell_labels = np.delete(cell_labels,indices_train) #dropping the training data points\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(values_predictions, cell_labels, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "0.4366807393703651"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "X_features = rbf_feature.fit_transform(values_predictions)\n",
    "clf = SGDClassifier(max_iter=1000)\n",
    "clf.fit(X_features, y)\n",
    "SGDClassifier(max_iter=1000)\n",
    "clf.score(X_features, y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [],
   "source": [
    "def get_elbow(curve):\n",
    "    # source:https://stackoverflow.com/questions/2018178/finding-the-best-trade-off-point-on-a-curve\n",
    "    nPoints = len(curve)\n",
    "    allCoord = np.vstack((range(nPoints), curve)).T\n",
    "    np.array([range(nPoints), curve])\n",
    "    firstPoint = allCoord[0]\n",
    "    lineVec = allCoord[-1] - allCoord[0]\n",
    "    lineVecNorm = lineVec / np.sqrt(np.sum(lineVec ** 2))\n",
    "    vecFromFirst = allCoord - firstPoint\n",
    "    scalarProduct = np.sum(vecFromFirst * np.matlib.repmat(lineVecNorm, nPoints, 1), axis=1)\n",
    "    vecFromFirstParallel = np.outer(scalarProduct, lineVecNorm)\n",
    "    vecToLine = vecFromFirst - vecFromFirstParallel\n",
    "    distToLine = np.sqrt(np.sum(vecToLine ** 2, axis=1))\n",
    "    idxOfBestPoint = np.argmax(distToLine)\n",
    "    return idxOfBestPoint\n",
    "\n",
    "def get_avg_split_arr(arr, num_splits):\n",
    "    array_split = np.array_split(arr, num_splits)\n",
    "    averages = [mean(array) for array in array_split]\n",
    "    return averages\n",
    "\n",
    "def get_EdU_threshold(edu_nums):\n",
    "    #edu_nums = np.sort(np.array(df.loc[:, [column_name]]).flatten())  # extract EdU values and put them in one array shape num_of_cells\n",
    "    # Get the list of EdU values\n",
    "    # Make a split from 3 to the total number of cells\n",
    "    # Get the averages at that split\n",
    "    # Get the elbow in those averages\n",
    "    # Store that elbow in a list\n",
    "    # Average out the list of elbow and return that value\n",
    "    elbows_y = []\n",
    "    start = round(0.73*len(edu_nums)) #we don't want to average out all of the cells because that would create a much a lower value so we only keep the top quarter\n",
    "    for i in range(start, len(edu_nums) + 1):\n",
    "        avg_split_arr = get_avg_split_arr(edu_nums, i)\n",
    "        elbow_x = get_elbow(avg_split_arr)\n",
    "        elbows_y.append(edu_nums[elbow_x])\n",
    "    return mean(elbows_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [],
   "source": [
    "\n",
    "def apply_rules(values_predictions):\n",
    "    #want to separate out the dapi values from the cyclin a2 values and the others etc.\n",
    "    dapi_values = values_predictions[:,0]\n",
    "    cyclina2_values = values_predictions[:,1]\n",
    "    edu_values = values_predictions[:,2]\n",
    "    dna_values = values_predictions[:,3]\n",
    "\n",
    "    edu_thresh = get_EdU_threshold(edu_values[:250])\n",
    "    cyclina2_thresh = get_EdU_threshold(cyclina2_values[:250])\n",
    "\n",
    "    preds = []\n",
    "    for i in range(len(values_predictions)):\n",
    "        if edu_values[i] >= edu_thresh: preds.append(1) #s\n",
    "        elif cyclina2_values[i] < cyclina2_thresh and edu_values[i] < edu_thresh and dna_values[i] < 1.5: preds.append(0) #g1\n",
    "        elif dna_values[i] > 1.5 and cyclina2_values[i] > cyclina2_thresh and edu_values[i] < edu_thresh: preds.append(2) #g2m\n",
    "\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [
    "cell_labels = get_cell_labels(df)\n",
    "indices = np.arange(len(pcna_crops_flat_pad))\n",
    "\n",
    "X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(pcna_crops_flat_pad, cell_labels, indices, test_size=0.5, random_state=42, shuffle=False)\n",
    "\n",
    "values_predictions = get_value_predictions(X_test,[dapi_mod,cyclina2_mod,edu_mod,dna_mod])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    X  y\n",
      "0   [0.07297884556833448, 0.21502774912679135, 0.0...  0\n",
      "1   [0.0936574029812724, 0.25611750030191666, 0.04...  0\n",
      "2   [0.10235550715260495, 0.21741169459594326, 0.0...  0\n",
      "3   [0.0746306168712752, 0.21827037606024718, 0.09...  0\n",
      "4   [0.05883775160158323, 0.1610087322680655, 0.01...  0\n",
      "5   [0.19211636390264408, 0.3190461898414219, 0.11...  0\n",
      "6   [0.07468121534336553, 0.2047367302888031, 0.09...  0\n",
      "7   [0.07348525783072753, 0.2257221851233472, 0.07...  0\n",
      "8   [0.07829013783588076, 0.2065336391920153, 0.06...  0\n",
      "9   [0.06554901224195551, 0.1972760959235117, 0.06...  0\n",
      "10  [0.0748519808713347, 0.1944836572266424, 0.057...  0\n",
      "11  [0.07428322736241541, 0.2054121124224478, 0.03...  0\n",
      "12  [0.07337421166564737, 0.19928498621839658, 0.0...  0\n",
      "13  [0.05024048345919645, 0.2070022426461826, 0.06...  0\n",
      "14  [0.07491501975437462, 0.1949924865625282, 0.07...  0\n",
      "15  [0.06642725550620043, 0.18841266345388183, 0.0...  0\n",
      "16  [0.07551358044857376, 0.16506382976472303, 0.0...  0\n",
      "17  [0.07175549309303034, 0.20173467897949338, 0.0...  0\n",
      "18  [0.07553251766806844, 0.19588673161384756, 0.0...  0\n",
      "19  [0.07241770814379536, 0.17740654392086566, 0.0...  0\n"
     ]
    }
   ],
   "source": [
    "X = values_predictions\n",
    "y = cell_labels\n",
    "\n",
    "df_test = pd.DataFrame(list(zip(X,y)),columns=['X','y'])\n",
    "print(df_test[:20])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.68790588065984\n"
     ]
    }
   ],
   "source": [
    "#Result from applying the rules\n",
    "#This may be due to the thresholds not being representative as we usually calculate them on one cell image not that man\n",
    "\n",
    "predictions_rules = apply_rules(X)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(predictions_rules)):\n",
    "    if predictions_rules[i] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct*100/len(predictions_rules))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "#Lets try randomforest\n",
    "#why am I not including PCNA in this??? thats the real next step hahaha\n",
    "\n",
    "#lets make a dataframe\n",
    "\n",
    "df_rfc = pd.DataFrame(list(zip(values_predictions[:,0],values_predictions[:,1],values_predictions[:,2],values_predictions[:,3],cell_labels)),columns=['dapi','cyclina2','edu','dna','labels'])\n",
    "\n",
    "X = df_rfc.iloc[:, 0:4].values\n",
    "y = df_rfc.iloc[:, 4].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "regressor = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "#print(confusion_matrix(y_test,y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.904577436951534\n"
     ]
    }
   ],
   "source": [
    "#print(classification_report(y_test,y_pred))\n",
    "correct = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct*100/len(y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#we also need to compare then with the ground truth values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#need to print a bunch of them with their predictions and their real value next to them\n",
    "#especially for the edu_mod one that seems terribly wrong"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#need to plot the predictions and the rest by showing how much they are off by"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Get train and test. Done\n",
    "\n",
    "#Time the first 1000 to see how long it will take us for the 138k. Not useful right now\n",
    "\n",
    "#could also augment with rotations, although they might be ignored here since the crop is flattened. Need to research this.\n",
    "\n",
    "#also need to make these predictions on other values, lets put all of this into a function. Done\n",
    "\n",
    "#instead of applying the rules, we could make a tiny NN that takes these 4 values and predicts the label\n",
    "\n",
    "#So to get the new data and only get the segmentations not the entire crop with the background I'll have to go back to Richmond and that will take another 4 hours\n",
    "#Anyway, for now I'm seeing if this is able to guess the cell label accordingly\n",
    "#Could try once with applying the rules\n",
    "\n",
    "#will try dropping some model predictions just to see if it performs better without them\n",
    "#to be faire a neural network would learn to ignore the useless ones\n",
    "\n",
    "#might be better to get confidence labels rather than hard classification\n",
    "#it would be cool to compare that with the confidence with the threshold (how far it is from the threshold) for the training data rules classification\n",
    "\n",
    "#will try applying the rules on those predictions after, could make a simple function now that we have the 'get_value_predictions' function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Later on we will want to just have the segmentations of the cells from the mask and not have the background, as in the background should just be zeros, that would probably even make this model more accurate"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}